{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f0cc42",
   "metadata": {},
   "source": [
    "# Using Jamba Instruct on Bedrock for SOP and Regulatory Document Analysis\n",
    "This notebook demonstrates the use of AI21's Jamba Instruct model to analyze Standard Operating Procedures (SOPs) against regulatory documents in the pharmaceutical industry for compliance verification.\n",
    "\n",
    "Jamba 1.5 Large from AI21 Labs is perfect for enterprises that need a model to process large amounts of data while providing high accuracy and speed. Its innovative SSM-Transformer hybrid architecture, combining elements of the Mamba architecture with traditional Transformer frameworks, ensures both quality and efficiency. With a 256K context window and 94 billion active parameters, Jamba 1.5 Large excels in tasks like multi-document analysis, question answering, and organizational data search, making it a cost-effective choice for handling complex, data-heavy queries.\n",
    "\n",
    "Vertex AI by Google Cloud is a fully managed AI platform that simplifies the machine learning lifecycle, from data preparation to model deployment and monitoring. It integrates seamlessly with other Google Cloud services, allowing businesses to leverage existing data and infrastructure while scaling their AI efforts. This makes Vertex AI ideal for organizations that need robust, scalable, and secure AI solutions to innovate and meet evolving business needs efficiently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ce977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import subprocess\n",
    "\n",
    "# Function to read the contents of the files\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Function to call GCP AI model\n",
    "def call_gcp_ai_model(prompt, **kwargs):\n",
    "    # Define the payload for the AI model request\n",
    "    payload = {\n",
    "        \"model\": \"models/YOUR_MODEL_NAME\",  # Specify your model here\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],  # Input prompt\n",
    "        \"max_tokens\": 1024,  # Maximum tokens for response\n",
    "        \"top_p\": 0.8,\n",
    "        \"temperature\": 0.7,\n",
    "    }\n",
    "    payload.update(kwargs)\n",
    "    request_json = json.dumps(payload)\n",
    "    \n",
    "    # Obtain an access token using GCP's gcloud command-line tool\n",
    "    access_token = subprocess.check_output(\n",
    "        [\"gcloud\", \"auth\", \"print-access-token\"]\n",
    "    ).decode('utf-8').strip()\n",
    "\n",
    "    # Define headers for the API request, including authorization with the access token\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Construct the endpoint URL for the AI model hosted on GCP\n",
    "    project_id = \"YOUR_PROJECT_ID\"  # Replace with your GCP project ID\n",
    "    location = \"YOUR_LOCATION\"  # e.g., \"us-central1\"\n",
    "    endpoint = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/YOUR_MODEL_NAME:predict\"\n",
    "    \n",
    "    # Make the POST request to the GCP endpoint\n",
    "    response = requests.post(endpoint, headers=headers, data=request_json)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return result['predictions'][0]['text']\n",
    "    else:\n",
    "        raise Exception(f\"Request failed with status code {response.status_code}: {response.text}\")\n",
    "\n",
    "# Function to handle retries\n",
    "def call_gcp_ai_model_with_retries(prompt, **kwargs):\n",
    "    attempts = 0\n",
    "    while attempts < 5:\n",
    "        try:\n",
    "            return call_gcp_ai_model(prompt, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            attempts += 1\n",
    "            print(f\"Attempt {attempts}: Failed to call API, retrying in 3 seconds...\")\n",
    "            time.sleep(3)\n",
    "    raise Exception(\"Failed to complete the API call after 5 attempts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the text files\n",
    "sample_sop_path = 'sample_sop.txt'\n",
    "subpart_path = 'Subpart_E_163_190.txt'\n",
    "\n",
    "# Read the contents of the files\n",
    "sample_sop_content = read_file(sample_sop_path)\n",
    "subpart_content = read_file(subpart_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1384769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt for the AI model\n",
    "prompt = f'Analyze the following SOP against the regulatory document for any contradictions: {sample_sop_content} against {subpart_content}'\n",
    "\n",
    "# Call the GCP AI model\n",
    "result = call_gcp_ai_model_with_retries(prompt)\n",
    "\n",
    "# Output the result\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
